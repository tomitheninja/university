{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c2Xnqu9En5i"
      },
      "source": [
        "# Gyakorló feladat\n",
        "Az https://archive.ics.uci.edu/ml/machine-learning-databases/00432/Data/News_Final.csv adatbázis tartalmazza (többek közt), hogy egy megjelent újságcikket, a rákövetkező héten hányan likeoltak a Facebookon. Hajts végre egy gépi tanulási kísérletet, hogy megtudjuk, hogy a `headline` szövege és a `source` alapján mennyire jól lehet megjósolni a `Facebook` likeok számát!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9sopGCiO9fu"
      },
      "source": [
        "# adat beolvasása\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00432/Data/News_Final.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB_dxbMV9fm_"
      },
      "source": [
        "\n",
        "Csak azokat a cikkeket használd, ahol pozitív a `Facebook` likeok száma! Tanító adatbázisnak használd a 2016 máriusáig megjelent (`PublishDate`) cikkeket és értékeld ki a 2016. ápr 1. utáni cikkeken!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddiuctelRcMl"
      },
      "source": [
        "# időpontként és ne string-ként kezeljük a PublishDate-et\n",
        "df.PublishDate = pd.to_datetime(df.PublishDate)\n",
        "\n",
        "# nem pozitív Facebook like értékkel bíró sorokat eldobjuk\n",
        "df = df[df.Facebook>0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVxClJF6awvF"
      },
      "source": [
        "# Tanító és kiértékelő adatbázisra vágunk\n",
        "traindf = df[df.PublishDate <= '2016-04-01']\n",
        "testdf = df[df.PublishDate > '2016-04-01']\n",
        "print(\"TanítóDB méretei:\", traindf.shape)\n",
        "print(\"KiértékelőDB méretei:\", testdf.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHtIbDuQPzI7"
      },
      "source": [
        "# Jellemzőkinyerés a headline és source szöveges mezőkből\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow_extractor = CountVectorizer()\n",
        "train_features = bow_extractor.fit_transform(traindf.Headline + traindf.Source) # string oszlopok összeadása a sorok szövegeinek összefűzését jelenti\n",
        "# ez elszáll a NaN-ok miatt..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX5hrfeckJqm"
      },
      "source": [
        "# dobjuk a NaNos sorokat\n",
        "traindf = traindf.dropna()\n",
        "testdf = testdf.dropna()\n",
        "print(\"TanítóDB méretei:\", traindf.shape)\n",
        "print(\"KiértékelőDB méretei:\", testdf.shape)\n",
        "# nem sokat veszítettünk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uQ0zyw7lBa4"
      },
      "source": [
        " # így már lefut\n",
        "train_features = bow_extractor.fit_transform(traindf.Headline + traindf.Source)\n",
        "print(train_features.shape)\n",
        "# 55ezer szavunk=jellemzőnk van"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYmQHsC4QWIr"
      },
      "source": [
        "# Regressziós modell tanulása\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression(normalize=True)\n",
        "reg.fit(train_features, traindf.Facebook) # Facebook oszlop a célváltozó\n",
        "# ez így nagyon lassú... inkább állítsuk le a futást."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7vgsIpjnhHK"
      },
      "source": [
        "# Csökkentsük a tanító adatbázis méretét, hogy lássunk valami eredményt!\n",
        "# vagy a sorok számát csökkentjük (traindf_small = traindf[:2000]) vagy a jellemzők számát\n",
        "# nézzük a jellemzőszámot 55ezerről hogy lehet csökkenteni:\n",
        "bow_extractor = CountVectorizer(min_df=10) # min_df=N esetén csak azok a szavak kerülnek be amelyek legalább N dokumentumban előfordulnak. A ritkák úgyis csak zajt hoznak be...\n",
        "train_features = bow_extractor.fit_transform(traindf.Headline + traindf.Source)\n",
        "print(train_features.shape) # így már csak 7254 jellemző maradt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQSLgXdhAB4_"
      },
      "source": [
        "# és gyorsan lefut a tanulás a teljes halmazon is\n",
        "reg = LinearRegression()\n",
        "reg.fit(train_features, traindf.Facebook)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIbXPsorm4Vn"
      },
      "source": [
        "# predikció és kiértékelés a kiértékelő adatbázisra\n",
        "test_features = bow_extractor.transform(testdf.Headline + testdf.Source) # a transform a fit-nél kiválasztott szavakat használja csak\n",
        "prediction = reg.predict(test_features)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(prediction, testdf.Facebook)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i80irS4-4r7"
      },
      "source": [
        "### Mindig hasonlítsuk az eredményt baselinehoz!\n",
        "from sklearn.dummy import DummyRegressor\n",
        "dummy = DummyRegressor(strategy='mean') # tanító adatbázis címkéinek átlaga lesz mindig a predikció\n",
        "dummy.fit(train_features, traindf.Facebook)\n",
        "mean_squared_error(dummy.predict(test_features), testdf.Facebook)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhIc8rtpAaxA"
      },
      "source": [
        "Sokkal rosszabb a tanuló, mint a baseline :(\n",
        "\n",
        "Mivel szövegekről van szó, érdemes lehet kipróbálni a regressziós döntési fát is (talán ennyi jellemzőre még lefut)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XOREwGf_zhI"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "reg = DecisionTreeRegressor(min_samples_leaf=5000) # döntési fa regresszióra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jNBZ3JPAF-j"
      },
      "source": [
        "reg.fit(train_features, traindf.Facebook)\n",
        "prediction = reg.predict(test_features)\n",
        "mean_squared_error(prediction, testdf.Facebook)\n",
        "# veri a baselinet ..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}